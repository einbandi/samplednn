{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian NN\n",
    "\n",
    "This notebook implements a simple, fully connected Bayesian neural network using `pyro` and `torch`.\n",
    "\n",
    "\n",
    "The network is trained on the _MNIST_ dataset. Network parameters are exported during training.<br>\n",
    "After training, sampled outputs are exported (for different training stages) to be used in an external visualization tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependecies\n",
    "\n",
    "Required modules:\n",
    "- `torch` for neural net functionality (including tensors)\n",
    "- `torchvision` to obtain the MNIST dataset and enable some tensor transformations\n",
    "- `pyro` for variational inference â€“ this makes the network Bayesian\n",
    "\n",
    "Additional modules:\n",
    "- `time` for timing operations (could be raplayed by `%time` in notebook)\n",
    "- `numpy` and `matplotlib.pyplot` to post-process and plot the data\n",
    "- `os` to parse directory names and list files\n",
    "- `csv` and/or `json` for data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions.constraints as constraints\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a neural network class and instantiate\n",
    "\n",
    "Fully connected, one hidden layer, relu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, use_cuda=False):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "            \n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = F.relu(output)\n",
    "        output = self.out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NN(28*28, 1024, 10, use_cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some activation functions\n",
    "\n",
    "- log softmax\n",
    "- softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "softplus = torch.nn.Softplus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define priors ond place over NN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "\n",
    "    fc1w_prior = dist.Normal(\n",
    "        loc=torch.zeros_like(net.fc1.weight),\n",
    "        scale=torch.ones_like(net.fc1.weight),\n",
    "    )\n",
    "    fc1b_prior = dist.Normal(\n",
    "        loc=torch.zeros_like(net.fc1.bias),\n",
    "        scale=torch.ones_like(net.fc1.bias),\n",
    "    )\n",
    "\n",
    "    outw_prior = dist.Normal(\n",
    "        loc=torch.zeros_like(net.out.weight),\n",
    "        scale=torch.ones_like(net.out.weight),\n",
    "    )\n",
    "    outb_prior = dist.Normal(\n",
    "        loc=torch.zeros_like(net.out.bias),\n",
    "        scale=torch.ones_like(net.out.bias),\n",
    "    )\n",
    "\n",
    "    priors = {\n",
    "        'fc1.weight': fc1w_prior,\n",
    "        'fc1.bias'  : fc1b_prior,\n",
    "        'out.weight': outw_prior,\n",
    "        'out.bias'  : outb_prior\n",
    "    }\n",
    "\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_model = pyro.random_module('module', net, priors)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    lifted_reg_model = lifted_model()\n",
    "\n",
    "    lhat = lifted_reg_model(x_data)\n",
    "\n",
    "    pyro.sample('obs', dist.Categorical(logits=lhat), obs=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define guide and initialize randomly\n",
    "\n",
    "_TODO:_ find out what `softplus` accomplishes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(x_data, y_data):\n",
    "    \n",
    "    # First layer weight distribution priors\n",
    "    fc1w_mean = torch.randn_like(net.fc1.weight)\n",
    "    fc1w_std = torch.abs(torch.randn_like(net.fc1.weight))\n",
    "    fc1w_mean_param = pyro.param('fc1w_mean', fc1w_mean)\n",
    "    fc1w_std_param = pyro.param('fc1w_std', fc1w_std, constraint=constraints.positive)\n",
    "    fc1w_prior = dist.Normal(\n",
    "        loc=fc1w_mean_param,\n",
    "        scale=fc1w_std_param\n",
    "    )\n",
    "\n",
    "    # First layer bias distribution priors\n",
    "    fc1b_mean = torch.randn_like(net.fc1.bias)\n",
    "    fc1b_std = torch.abs(torch.randn_like(net.fc1.bias))\n",
    "    fc1b_mean_param = pyro.param('fc1b_mean', fc1b_mean)\n",
    "    fc1b_std_param = pyro.param('fc1b_std', fc1b_std, constraint=constraints.positive)\n",
    "    fc1b_prior = dist.Normal(\n",
    "        loc=fc1b_mean_param,\n",
    "        scale=fc1b_std_param\n",
    "    )\n",
    "\n",
    "    # Output layer weight distribution priors\n",
    "    outw_mean = torch.randn_like(net.out.weight)\n",
    "    outw_std = torch.abs(torch.randn_like(net.out.weight))\n",
    "    outw_mean_param = pyro.param('outw_mean', outw_mean)\n",
    "    outw_std_param = pyro.param('outw_std', outw_std, constraint=constraints.positive)\n",
    "    outw_prior = dist.Normal(\n",
    "        loc=outw_mean_param,\n",
    "        scale=outw_std_param\n",
    "    )\n",
    "\n",
    "    # Output layer bias distribution priors\n",
    "    outb_mean = torch.randn_like(net.out.bias)\n",
    "    outb_std = torch.abs(torch.randn_like(net.out.bias))\n",
    "    outb_mean_param = pyro.param('outb_mean', outb_mean)\n",
    "    outb_std_param = pyro.param('outb_std', outb_std, constraint=constraints.positive)\n",
    "    outb_prior = dist.Normal(\n",
    "        loc=outb_mean_param,\n",
    "        scale=outb_std_param\n",
    "    )\n",
    "\n",
    "    priors = {\n",
    "        'fc1.weight': fc1w_prior,\n",
    "        'fc1.bias'  : fc1b_prior,\n",
    "        'out.weight': outw_prior,\n",
    "        'out.bias'  : outb_prior\n",
    "    }\n",
    "\n",
    "    lifted_module = pyro.random_module('module', net, priors)\n",
    "\n",
    "    return lifted_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose optimization parameters\n",
    "\n",
    "- Adam optimizer ([Kingma & Ba, 2014](https://arxiv.org/abs/1412.6980))\n",
    "    - Learning rate: 0.001\n",
    "- Stochastic variational inference\n",
    "    - Expectation lower bound (ELBO) as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = pyro.optim.Adam({'lr': 0.001})\n",
    "svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct loaders for training and test data\n",
    "\n",
    "- Dataset: MNIST\n",
    "- Batch size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "use_cuda = True\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': use_cuda, 'batch_size': batch_size}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './mnist-data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    ),\n",
    "    shuffle=True,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './mnist-data',\n",
    "        train=False,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    ),\n",
    "    shuffle=False,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training\n",
    "\n",
    "If experiments are rerun, the parameter store has to be cleared first (uncomment first line).<br>\n",
    "Possibly uncomment lines for exporting network data and adapt export granularity.<br>\n",
    "Set number of epochs via `num_iterations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................\n",
      "Epoch  0  Loss  6493.183268421574\n",
      "Time taken: 10.154435157775879 s\n",
      "................\n",
      "Epoch  1  Loss  4713.582906363217\n",
      "Time taken: 19.771262645721436 s\n",
      "................\n",
      "Epoch  2  Loss  3484.526981917675\n",
      "Time taken: 29.354207038879395 s\n",
      "................\n",
      "Epoch  3  Loss  2584.2780761197646\n",
      "Time taken: 39.05123591423035 s\n",
      "................\n",
      "Epoch  4  Loss  1923.5260506713312\n",
      "Time taken: 48.690467834472656 s\n",
      "................\n",
      "Epoch  5  Loss  1436.5318848463216\n",
      "Time taken: 58.78489065170288 s\n",
      "................\n",
      "Epoch  6  Loss  1080.2607213371198\n",
      "Time taken: 69.09088921546936 s\n",
      "................\n",
      "Epoch  7  Loss  818.5022287346601\n",
      "Time taken: 78.94313597679138 s\n",
      "................\n",
      "Epoch  8  Loss  626.825169472154\n",
      "Time taken: 88.77480125427246 s\n",
      "................\n",
      "Epoch  9  Loss  486.18120333329836\n",
      "Time taken: 98.71620869636536 s\n",
      "................\n",
      "Epoch  10  Loss  382.3653835990429\n",
      "Time taken: 108.69900894165039 s\n",
      "................\n",
      "Epoch  11  Loss  305.231566237402\n",
      "Time taken: 119.38548731803894 s\n",
      "................\n",
      "Epoch  12  Loss  246.9847327015082\n",
      "Time taken: 129.86844420433044 s\n",
      "................\n",
      "Epoch  13  Loss  204.81325659654937\n",
      "Time taken: 141.9944155216217 s\n",
      "................\n",
      "Epoch  14  Loss  172.04177744178773\n",
      "Time taken: 152.06344318389893 s\n"
     ]
    }
   ],
   "source": [
    "# pyro.clear_param_store()\n",
    "# pyro.get_param_store().load('saved-params-bs128/params_ep6_batch00450')\n",
    "\n",
    "num_iterations = 15\n",
    "loss = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for j in range(num_iterations):\n",
    "    loss = 0\n",
    "    for batch_id, data in enumerate(train_loader):\n",
    "        # calculate the loss and take a gradient step\n",
    "        images = data[0].view(-1,28*28)\n",
    "        labels = data[1]\n",
    "        \n",
    "        if use_cuda:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        loss += svi.step(images, labels)\n",
    "        if batch_id % 30 == 0:\n",
    "            print('.', end='')\n",
    "    \n",
    "    #filename = 'saved-params-bs{}_NEW/params_ep{:02}'.format(batch_size, j)\n",
    "    #pyro.get_param_store().save(filename)\n",
    "    #print('saved parameter store to {}'.format(filename))\n",
    "    \n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = loss / normalizer_train\n",
    "        \n",
    "    print('\\nEpoch ', j, ' Loss ', total_epoch_loss_train)\n",
    "    print('Time taken: {} s'.format(time.time()-start_time))\n",
    "    \n",
    "#filename = 'saved-params-bs%d_NEW/params_after_ep%d' % (batch_size, 11 + num_iterations - 1)\n",
    "#pyro.get_param_store().save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Predict\n",
    "\n",
    "Prediction is performed by simply choosing the class with the highest score (from the score average over drawn samples).<br>\n",
    "`num_samples` governs the number of samples to be drawn for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_outputs(x, num_samples=10):\n",
    "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    return torch.stack(yhats)\n",
    "\n",
    "# average logits, then take argmax\n",
    "def predict(x, num_samples=10):\n",
    "    yhats = sample_outputs(x, num_samples=num_samples)\n",
    "    mean = torch.mean(yhats, 0)\n",
    "    if use_cuda:\n",
    "        mean = mean.cpu()\n",
    "    return np.argmax(mean.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform test while forcing the network to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction when network is forced to predict\n",
      "...........................\n",
      "length of test set: 10000\n",
      "accuracy for num_samples = 20: 91 %\n",
      "Time taken for predictions: 5.1039416790008545\n"
     ]
    }
   ],
   "source": [
    "num_samples = 20\n",
    "\n",
    "print('Prediction when network is forced to predict')\n",
    "start_time = time.time()\n",
    "correct = 0\n",
    "total = 0\n",
    "for j, data in enumerate(test_loader):\n",
    "    images, labels = data\n",
    "    if use_cuda:\n",
    "        images = images.view(-1,28*28).cuda()\n",
    "    else:\n",
    "        images = images.view(-1,28*28)\n",
    "    outputs = predict(images, num_samples=num_samples)\n",
    "    total += labels.size(0)\n",
    "    correct += (np.asarray(outputs) == np.asarray(labels)).sum().item()\n",
    "    if j % 3 == 0: print('.', end='')\n",
    "\n",
    "print('\\nlength of test set: {}'.format(total))\n",
    "print('accuracy for num_samples = %d: %d %%' % (num_samples, 100 * correct / total))\n",
    "print('Time taken for predictions: {}'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Alternatively, predict by averaging softmaxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\n",
      "length of test set: 89952\n",
      "accuracy for num_samples = 100: 64 %\n",
      "Time taken for predictions: 23.941030502319336\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for j , data in enumerate(test_loader):\n",
    "    images, labels = data\n",
    "    if use_cuda:\n",
    "        images = images.view(-1,28*28).cuda()\n",
    "    else:\n",
    "        images = images.view(-1,28*28)\n",
    "    yhats = sample_outputs(images, num_samples=num_samples)\n",
    "    softmax = nn.Softmax(dim=2)(yhats)\n",
    "    mean = torch.mean(softmax, 0)\n",
    "    if use_cuda:\n",
    "        mean = mean.cpu()\n",
    "    prediction = np.argmax(mean.numpy(), axis=1)\n",
    "    total += labels.size(0)\n",
    "    correct += (np.asarray(prediction) == np.asarray(labels)).sum().item()\n",
    "    if j % 3 == 0: print('.', end='')\n",
    "        \n",
    "print('\\nlength of test set: {}'.format(total))\n",
    "print('accuracy for num_samples = %d: %d %%' % (num_samples, 100 * correct / total))\n",
    "print('Time taken for predictions: {}'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain \"nice\" lists of trianing and test examples\n",
    "\n",
    "Define some custom data loaders for obtaining single training and test instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './mnist-data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "single_test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './mnist-data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each class, obtain a certain number of training and test examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_label = {\n",
    "    'train': 1000,\n",
    "    'test': 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = [[] for _ in range(10)]\n",
    "index_counts = [0 for _ in range(10)]\n",
    "\n",
    "for index, batch in enumerate(single_train_loader):\n",
    "    image, label = batch\n",
    "    if index_counts[label] < samples_per_label['train']:\n",
    "        # sample_indices[label][index_counts[label]] = index\n",
    "        training_images[label].append(image)\n",
    "        index_counts[label] += 1\n",
    "\n",
    "test_images = [[] for _ in range(10)]\n",
    "index_counts = [0 for _ in range(10)]\n",
    "\n",
    "for index, batch in enumerate(single_test_loader):\n",
    "    image, label = batch\n",
    "    if index_counts[label] < samples_per_label['test']:\n",
    "        # sample_indices[label][index_counts[label]] = index\n",
    "        test_images[label].append(image)\n",
    "        index_counts[label] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the training and test image lists. After this step, they each have shape `(10 * samples_per_label['train'|'test'], 28*28)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = torch.stack([image.view(-1,28*28) for digit_class in training_images for image in digit_class])\n",
    "\n",
    "test_images = torch.stack([image.view(-1,28*28) for digit_class in test_images for image in digit_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample some ouputs\n",
    "\n",
    "Sample some outputs for the previously obtained training and test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time: 2.370715618133545 s\n",
      "\n",
      "Elapsed time: 1.735379695892334 s\n"
     ]
    }
   ],
   "source": [
    "num_samples = 20\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "training_outputs = []\n",
    "for _ in range(num_samples):\n",
    "    model = guide(None, None)\n",
    "    training_outputs.append(model(training_images))\n",
    "training_outputs = torch.stack(training_outputs).transpose(0,1).flatten(start_dim=2)\n",
    "\n",
    "print('\\nElapsed time: {} s'.format(time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "test_outputs = []\n",
    "for _ in range(num_samples):\n",
    "    model = guide(None, None)\n",
    "    test_outputs.append(model(test_images))\n",
    "test_outputs = torch.stack(test_outputs).transpose(0,1).flatten(start_dim=2)\n",
    "\n",
    "print('\\nElapsed time: {} s'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain epoch-wise data\n",
    "\n",
    "Select directory with saved parameters (possibly adapt `batch_size` before) and select only those at end of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '.\\saved-params-bs' + str(batch_size) + '_NEW'\n",
    "parsed_dir = os.fsencode(directory)\n",
    "\n",
    "# epoch_endstate_files = [s for s in os.listdir(parsed_dir) if '450' in s.decode()]\n",
    "epoch_endstate_files = [s for s in os.listdir(parsed_dir) if 'before' in s.decode()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'params_before_ep00',\n",
       " b'params_before_ep01',\n",
       " b'params_before_ep02',\n",
       " b'params_before_ep03',\n",
       " b'params_before_ep04',\n",
       " b'params_before_ep05',\n",
       " b'params_before_ep06',\n",
       " b'params_before_ep07',\n",
       " b'params_before_ep08',\n",
       " b'params_before_ep09',\n",
       " b'params_before_ep10',\n",
       " b'params_before_ep11',\n",
       " b'params_before_ep12',\n",
       " b'params_before_ep13',\n",
       " b'params_before_ep14',\n",
       " b'params_before_ep15']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_endstate_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each saved network state in `epoch_endstate_files`, pass all `training_images` through the Bayesian NN, each time sampling `num_samples` outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................\n",
      "Elapsed time: 42.52355217933655 s\n"
     ]
    }
   ],
   "source": [
    "num_samples = 20\n",
    "\n",
    "start_time = time.time()\n",
    "epoch_training_outputs = []\n",
    "for index, file in enumerate(epoch_endstate_files):\n",
    "    filename = os.fsdecode(file)\n",
    "    pyro.get_param_store().load(directory + '/' + filename)\n",
    "    yhats = sample_outputs(training_images, num_samples=num_samples)\n",
    "    epoch_training_outputs.append(yhats)\n",
    "    print('.', end='')\n",
    "print('\\nElapsed time: {} s'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape epoch-wise data.<br>\n",
    "New shape is `N_images * N_epochs * num_samples * dim_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_training_outputs = torch.stack(epoch_training_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_training_outputs = epoch_training_outputs.transpose(2,0).transpose(2,1).flatten(start_dim=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export everything\n",
    "\n",
    "Save the outputs using `torch.save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exported-data/training_outputs_NEW.npy', 'wb') as file:\n",
    "    np.save(file, training_outputs.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exported-data/test_outputs_NEW.npy', 'wb') as file:\n",
    "    np.save(file, test_outputs.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exported-data/training_outputs_epoch_NEW.npy', 'wb') as file:\n",
    "    np.save(file, epoch_training_outputs.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exported-data/training_inputs.npy', 'wb') as file:\n",
    "    np.save(file, training_images.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exported-data/test_inputs.npy', 'wb') as file:\n",
    "    np.save(file, test_images.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_training_data = np.load('training_outputs_epoch.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_training_data_for_json = []\n",
    "for index, image in enumerate(epoch_training_data):\n",
    "    entry = dict()\n",
    "    entry['index'] = index\n",
    "    # entry['image'] = training_images[index].tolist()\n",
    "    entry['data'] = []\n",
    "    for epoch, outputs in enumerate(image):\n",
    "        subentry = dict()\n",
    "        subentry['epoch'] = epoch\n",
    "        subentry['outputs'] = outputs.tolist()\n",
    "        entry['data'].append(subentry)\n",
    "    epoch_training_data_for_json.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NEW_complete_training_data.json', 'w') as outfile:\n",
    "    json.dump(epoch_training_data_for_json, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

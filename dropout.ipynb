{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNwithDropout(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, p=0.0, use_cuda=False):\n",
    "        super(NNwithDropout, self).__init__()\n",
    "        self.p = p\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "                \n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "            \n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = F.relu(F.dropout(output, p=self.p, training=True))\n",
    "        output = self.out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vector(t):\n",
    "    return t.view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "use_cuda = True\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': use_cuda, 'batch_size': batch_size}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './mnist-data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    ),\n",
    "    shuffle=True,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './mnist-data',\n",
    "        train=False,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    ),\n",
    "    shuffle=False,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NNwithDropout(28*28, 1024, 10, p=0.5, use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after Ep. 0: 45.80068784579635\n",
      "Loss after Ep. 1: 43.029464315623045\n",
      "Loss after Ep. 2: 40.64955406636\n",
      "Loss after Ep. 3: 38.087418584153056\n",
      "Loss after Ep. 4: 35.977309830486774\n",
      "Loss after Ep. 5: 34.169311521574855\n",
      "Loss after Ep. 6: 32.68178976140916\n",
      "Loss after Ep. 7: 30.914681425318122\n",
      "Loss after Ep. 8: 30.36680606007576\n",
      "Loss after Ep. 9: 28.714897906407714\n",
      "Loss after Ep. 10: 27.627061719074845\n",
      "Loss after Ep. 11: 26.463005805388093\n",
      "Loss after Ep. 12: 25.56579397059977\n",
      "Loss after Ep. 13: 24.21134540066123\n",
      "Loss after Ep. 14: 23.456627294421196\n",
      "Loss after Ep. 15: 22.99835648946464\n",
      "Loss after Ep. 16: 21.996352955698967\n",
      "Loss after Ep. 17: 21.128285998478532\n",
      "Loss after Ep. 18: 20.520638460293412\n",
      "Loss after Ep. 19: 20.415224539116025\n",
      "Loss after Ep. 20: 19.50062849279493\n",
      "Loss after Ep. 21: 18.60268199443817\n",
      "Loss after Ep. 22: 18.01242395211011\n",
      "Loss after Ep. 23: 17.389047322794795\n",
      "Loss after Ep. 24: 16.90783824585378\n",
      "Loss after Ep. 25: 16.30215534940362\n",
      "Loss after Ep. 26: 16.50446315575391\n",
      "Loss after Ep. 27: 15.808240430429578\n",
      "Loss after Ep. 28: 15.632818333804607\n",
      "Loss after Ep. 29: 15.002739449962974\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        images = images.view(-1,28*28) \n",
    "        if use_cuda:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print('Loss after Ep. {}: {}'.format(epoch, running_loss))\n",
    "    running_loss = 0.0\n",
    "        \n",
    "        #if i % 100 == 99:\n",
    "        #    print('[{}, {}] loss: {}'.format(epoch, i, running_loss/100))\n",
    "        #    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set with 50 samples for prediction: 0.996483325958252\n"
     ]
    }
   ],
   "source": [
    "# accuracy on train set\n",
    "num_samples = 50\n",
    "\n",
    "train_outputs = []\n",
    "train_labels = []\n",
    "\n",
    "train_predictions = []\n",
    "for data in train_loader:\n",
    "    img, lbl = data\n",
    "    train_labels.append(lbl)\n",
    "    current_prediction = []\n",
    "    img = img.view(-1, 28*28).cuda()\n",
    "    with torch.no_grad():\n",
    "        [current_prediction.append(net(img).cpu()) for _ in range(num_samples)]\n",
    "    train_predictions.append(torch.stack(current_prediction).transpose(0,1))\n",
    "    \n",
    "train_predictions = torch.cat(train_predictions)\n",
    "train_labels = torch.cat(train_labels)\n",
    "predicted_train_labels = train_predictions.mean(1).argmax(1)\n",
    "train_accuracy = (train_labels == predicted_train_labels).sum().float() / len(train_labels)\n",
    "\n",
    "print('Accuracy on train set with {} samples for prediction: {}'.format(num_samples, train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set with 50 samples for prediction: 0.9829000234603882\n"
     ]
    }
   ],
   "source": [
    "# accuracy on test set\n",
    "num_samples = 50\n",
    "\n",
    "test_outputs = []\n",
    "test_labels = []\n",
    "\n",
    "test_predictions = []\n",
    "for data in test_loader:\n",
    "    img, lbl = data\n",
    "    test_labels.append(lbl)\n",
    "    current_prediction = []\n",
    "    img = img.view(-1, 28*28).cuda()\n",
    "    with torch.no_grad():\n",
    "        [current_prediction.append(net(img).cpu()) for _ in range(num_samples)]\n",
    "    test_predictions.append(torch.stack(current_prediction).transpose(0,1))\n",
    "    \n",
    "test_predictions = torch.cat(test_predictions)\n",
    "test_labels = torch.cat(test_labels)\n",
    "predicted_test_labels = test_predictions.mean(1).argmax(1)\n",
    "test_accuracy = (test_labels == predicted_test_labels).sum().float() / len(test_labels)\n",
    "\n",
    "print('Accuracy on test set with {} samples for prediction: {}'.format(num_samples, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8238, 0.6741, 0.9447, 1.0293, 0.9717, 1.1997, 1.0119, 1.0451, 0.9248,\n",
       "        1.0264])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions[1].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
